{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Code the Fundamentals of Computer Vision \u00b6 This is the text for Code Everything: Fundamentals of Computer Vision . This text will teach you the fundamentals of computer vision from first principles by having you implement each technique and peice of theory from scratch, using as few libraries as is reasonably possible. Use the site navigation to continue reading, and if you are just beginning, do start from the Introduction .","title":"Home"},{"location":"#code-the-fundamentals-of-computer-vision","text":"This is the text for Code Everything: Fundamentals of Computer Vision . This text will teach you the fundamentals of computer vision from first principles by having you implement each technique and peice of theory from scratch, using as few libraries as is reasonably possible. Use the site navigation to continue reading, and if you are just beginning, do start from the Introduction .","title":"Code the Fundamentals of Computer Vision"},{"location":"000_introduction/introduction/","text":"Code Everything \u00b6 It is said that one doesn't really know a subject until they teach it. I argue similarly for any concept that can be programmed: deep mastery of such concepts comes from programming them ourselves. Programming is, in a sense, teaching computers. In this text, we work through the fundamentals of computer vision by coding them all on our own. Where reasonable, we use no supplementary software libraries until we have implemented some functionality of them ourselves. In this way, we build a deeper technical understanding of what the libraries are doing behind their APIs. About the Author \u00b6 I am a computer engineer by education and a software engineer by profession. I have mostly focused on embedded and systems programming in my career to date (2021). I had the opportunity to join a machine learning team for perception in autonomous vehicles, and my interest in computer vision and machine learning led me to pursue that opportunity. With no formal background in or experience with computer vision, I had to teach myself on the job and after hours. This text is a result of my journey, prepared for others who may find themselves in my former shoes or sympathize with my approach to learning. Prerequisites \u00b6 This text won't teach the fundamentals of computer science, nay, programming. You must be able to write your own general programs. You may implement the material in this text using whichever language you are most comfortable with. I will give demonstrations in Python 3 with occassional explanation in C or C++. I expect the reader to have general readability in languages like Python to follow along. In our journey, we will use some third-party Python libraries like NumPy and OpenCV 2 and also image-manipulation software like GIMP . Organization \u00b6 Every section that contains something to be coded is organized into three subsections. The first is Theory which explains a concept. The second is Challenge which presents the reader with a coding challenge based on the material in Theory . And the last is Implementation which demonstrates one way to solve the problem statement in Challenge .","title":"Introduction"},{"location":"000_introduction/introduction/#code-everything","text":"It is said that one doesn't really know a subject until they teach it. I argue similarly for any concept that can be programmed: deep mastery of such concepts comes from programming them ourselves. Programming is, in a sense, teaching computers. In this text, we work through the fundamentals of computer vision by coding them all on our own. Where reasonable, we use no supplementary software libraries until we have implemented some functionality of them ourselves. In this way, we build a deeper technical understanding of what the libraries are doing behind their APIs.","title":"Code Everything"},{"location":"000_introduction/introduction/#about-the-author","text":"I am a computer engineer by education and a software engineer by profession. I have mostly focused on embedded and systems programming in my career to date (2021). I had the opportunity to join a machine learning team for perception in autonomous vehicles, and my interest in computer vision and machine learning led me to pursue that opportunity. With no formal background in or experience with computer vision, I had to teach myself on the job and after hours. This text is a result of my journey, prepared for others who may find themselves in my former shoes or sympathize with my approach to learning.","title":"About the Author"},{"location":"000_introduction/introduction/#prerequisites","text":"This text won't teach the fundamentals of computer science, nay, programming. You must be able to write your own general programs. You may implement the material in this text using whichever language you are most comfortable with. I will give demonstrations in Python 3 with occassional explanation in C or C++. I expect the reader to have general readability in languages like Python to follow along. In our journey, we will use some third-party Python libraries like NumPy and OpenCV 2 and also image-manipulation software like GIMP .","title":"Prerequisites"},{"location":"000_introduction/introduction/#organization","text":"Every section that contains something to be coded is organized into three subsections. The first is Theory which explains a concept. The second is Challenge which presents the reader with a coding challenge based on the material in Theory . And the last is Implementation which demonstrates one way to solve the problem statement in Challenge .","title":"Organization"},{"location":"001_image_basics/about_images/","text":".katex img { object-fit: fill; padding: unset; display: block; position: absolute; width: 100%; height: inherit; } .bordered { border: 1px solid; } .square { width: 20px; height: 20px; } .black { background: #000000; } .red { background: #ff0000; } .green { background: #00ff00; } .blue { background: #0000ff; } .yellow { background: #ffff00; } .cyan { background: #00ffff; } .purple { background: #ff00ff; } .white { background: #ffffff; } .light-blue { background: #55aaff; } About Images \u00b6 Images \u00b6 Images are our fundamental input in this text. Image files contain (1) metadata about the image and (2) pixel data. Metadata includes properties such as the dimensions of the image and the binary format the pixel data is stored in. \"Pixel\" is a combination of the word \"picture\" and \"element\" and describes the smallest renderable element in an image. A 640x480 image is 640 pixels wide by 480 pixels tall. Each pixel in the pixel data describes its renderable element in terms of a combination of intensities of fundamental colors (like amount of red, green, and blue) or properties (like hue, saturation, and value). Right now, let's consider pixels that encode color information using fundamental colors. The fundamental colors come from a color model. A color model defines a way to represent a color in a spectrum by combining intensities of a select few colors, the fundamental colors of the model. Some popular color models are RGB (red, green, blue) and CMY (cyan, magenta, yellow), in this case named after their fundamenal colors. Color Representation \u00b6 Let's explore color representation more deeply. Consider the RGB color model. This model represents white as a combination of maximum intensities of all three fundamental colors. If we represent the intensities in a tuple-like form of (%R, %G, %B) with each element in the range [0.0, 1.0] , white would be (1.0, 1.0, 1.0) . Black is the absence of any color, in this case (0.0, 0.0, 0.0) . With a representation like this, one that uses percentages of arbitrary precision, our color spectrum is technically infinitely wide, since (0.1, 0.0, 0.0) , (0.01, 0.0, 0.0) , (0.001, 0.0, 0.0) , etc. all specify unique colors. We don't usually represent colors like this in files on our computers though. The reasons are numerous, but two important ones are that (1) for a variety of purposes far more efficient representations of intensities meet our needs and (2) after some point humans can no longer visually distinguish between two subtly-different shades of color, and therefore having the ability to encode those unique colors is moot if we are only interested in casual visual consumption. We make our spectrum of colors finite by representing intensities with integers in some bounded domain. For example, if we only allow fundamental colors to be zero intensity or maximum intensity, our range is [0, 1] . The possible colors using the RGB color model are then: (R, G, B) Color English Name (0, 0, 0) Black (1, 0, 0) Red (0, 1, 0) Green (0, 0, 1) Blue (1, 1, 0) Yellow (0, 1, 1) Cyan (1, 0, 1) Purple (1, 1, 1) White Using this scheme, we can represent a pixel using only 3 bits. In other words, our representation is 3 bits per pixel (bpp) . Each element R , G , and B is called a color channel, so we have a 1 bit per channel (bpc) representation. If we represented a 640x480 image using this scheme, the pixel data would consume 640 \u22c5 480 pixels \u22c5 3 bpp 8 bits per byte = 115 , 200 bytes \\dfrac {640 \\cdot 480 \\text { pixels} \\cdot 3 \\text { bpp}}{8 \\text { bits per byte}} = 115,200 \\text { bytes} 8 bits per byte 640 \u22c5 480 pixels \u22c5 3 bpp \u200b = 115 , 200 bytes or approximately 115 kB worth of space, uncompressed. If we were to have used high-precision floating-point numbers, such as a 64-bit double in C or C++ parlance, for each channel intensity value to represent them as precise percentages, our image would consume 64 times more space, roughly 7.4 MB! With our 3 bpp scheme, we have only 2 choices ( 1 or 0 ) for each channel of a pixel, giving us a total of 2 bpp = 2 bpc \u22c5 num channels = 2 1 \u22c5 3 = 2 3 = 8 2^{\\text {bpp}} = 2^{\\text {bpc } \\cdot \\text { num channels}} = 2^{1 \\cdot 3} = 2^{3} = 8 2 bpp = 2 bpc \u22c5 num channels = 2 1 \u22c5 3 = 2 3 = 8 unique colors. If we instead used 24 bpp, our spectrum would contain over 16 million colors, and the hypothetical 640x480 image would be approximately 921 kB. The below image simulates--by limiting the color palette--the effect various bit-per-pixel values may have on rendering a particular image. From left to right: 128 colors, 64 colors, 32 colors, and finally 16 colors. Interpreting Pixel Values \u00b6 Although we don't represent channel intensity values directly as percentages, they are implicit fractions. Using an 8 bpc scheme, the possible intensity values are between [ 0 , 2 bpc \u2212 1 ] = [ 0 , 2 8 \u2212 1 ] = [ 0 , 255 ] \\left[0,\\ 2^{\\text {bpc}} - 1\\right] = \\left[0,\\ 2^{8} - 1\\right] = \\left[0, 255\\right] [ 0 , 2 bpc \u2212 1 ] = [ 0 , 2 8 \u2212 1 ] = [ 0 , 255 ] If our color mode is RGB, we can mentally visualize the pixel (85, 170, 255) as being [ r 2 bpc \u2212 1 , g 2 bpc \u2212 1 , b 2 bpc \u2212 1 ] = [ 85 2 8 \u2212 1 , 170 2 8 \u2212 1 , 255 2 8 \u2212 1 ] \u2248 [ 0.3 , 0.6 , 1.0 ] \\left[\\frac{r}{2^{\\text {bpc}} - 1}, \\frac{g}{2^{\\text {bpc}} - 1}, \\frac{b}{2^{\\text {bpc}} - 1}\\right] = \\left[\\frac{85}{2^{8} - 1}, \\frac{170}{2^{8} - 1}, \\frac{255}{2^{8} - 1}\\right] \\approx \\left[0.3, 0.6, 1.0\\right] [ 2 bpc \u2212 1 r \u200b , 2 bpc \u2212 1 g \u200b , 2 bpc \u2212 1 b \u200b ] = [ 2 8 \u2212 1 85 \u200b , 2 8 \u2212 1 170 \u200b , 2 8 \u2212 1 255 \u200b ] \u2248 [ 0.3 , 0.6 , 1.0 ] which is a little bit of red, a moderate ammount of green, and a lot of blue, yielding the color below. (R, G, B) Color English Name (0.3, 0.6, 1.0) Light Blue Image Metadata \u00b6 If we encounter the pixel data (1, 2, 3, 4) in the wild, how do we interpret it? For example, what is this new fourth element that we haven't dealt with yet? Are the elements RGBA intensities, or maybe CMYK, or something else? The pixel data is valid using a 3 bpc / 12 bpp scheme, but does that scheme really give us the intended upper limits? The pixel is also valid (but semantically different) if interpretted using an 8 bpc / 32 bpp scheme. Image metadata answers all of these questions for us and in general teaches us how to interpret not only an image's pixel data but even other parts of its metadata. As we know, there are multiple popular image file formats (for example, bitmaps, JPEG, and PNG) in circulation today. Most image formats have their own metadata schema, and many of those schemas have multiple schema versions as a result of their filetypes evolving over the years. This alone makes parsing images nontrivial. We will experience this firsthand in the next section.","title":"About Images"},{"location":"001_image_basics/about_images/#about-images","text":"","title":"About Images"},{"location":"001_image_basics/about_images/#images","text":"Images are our fundamental input in this text. Image files contain (1) metadata about the image and (2) pixel data. Metadata includes properties such as the dimensions of the image and the binary format the pixel data is stored in. \"Pixel\" is a combination of the word \"picture\" and \"element\" and describes the smallest renderable element in an image. A 640x480 image is 640 pixels wide by 480 pixels tall. Each pixel in the pixel data describes its renderable element in terms of a combination of intensities of fundamental colors (like amount of red, green, and blue) or properties (like hue, saturation, and value). Right now, let's consider pixels that encode color information using fundamental colors. The fundamental colors come from a color model. A color model defines a way to represent a color in a spectrum by combining intensities of a select few colors, the fundamental colors of the model. Some popular color models are RGB (red, green, blue) and CMY (cyan, magenta, yellow), in this case named after their fundamenal colors.","title":"Images"},{"location":"001_image_basics/about_images/#color-representation","text":"Let's explore color representation more deeply. Consider the RGB color model. This model represents white as a combination of maximum intensities of all three fundamental colors. If we represent the intensities in a tuple-like form of (%R, %G, %B) with each element in the range [0.0, 1.0] , white would be (1.0, 1.0, 1.0) . Black is the absence of any color, in this case (0.0, 0.0, 0.0) . With a representation like this, one that uses percentages of arbitrary precision, our color spectrum is technically infinitely wide, since (0.1, 0.0, 0.0) , (0.01, 0.0, 0.0) , (0.001, 0.0, 0.0) , etc. all specify unique colors. We don't usually represent colors like this in files on our computers though. The reasons are numerous, but two important ones are that (1) for a variety of purposes far more efficient representations of intensities meet our needs and (2) after some point humans can no longer visually distinguish between two subtly-different shades of color, and therefore having the ability to encode those unique colors is moot if we are only interested in casual visual consumption. We make our spectrum of colors finite by representing intensities with integers in some bounded domain. For example, if we only allow fundamental colors to be zero intensity or maximum intensity, our range is [0, 1] . The possible colors using the RGB color model are then: (R, G, B) Color English Name (0, 0, 0) Black (1, 0, 0) Red (0, 1, 0) Green (0, 0, 1) Blue (1, 1, 0) Yellow (0, 1, 1) Cyan (1, 0, 1) Purple (1, 1, 1) White Using this scheme, we can represent a pixel using only 3 bits. In other words, our representation is 3 bits per pixel (bpp) . Each element R , G , and B is called a color channel, so we have a 1 bit per channel (bpc) representation. If we represented a 640x480 image using this scheme, the pixel data would consume 640 \u22c5 480 pixels \u22c5 3 bpp 8 bits per byte = 115 , 200 bytes \\dfrac {640 \\cdot 480 \\text { pixels} \\cdot 3 \\text { bpp}}{8 \\text { bits per byte}} = 115,200 \\text { bytes} 8 bits per byte 640 \u22c5 480 pixels \u22c5 3 bpp \u200b = 115 , 200 bytes or approximately 115 kB worth of space, uncompressed. If we were to have used high-precision floating-point numbers, such as a 64-bit double in C or C++ parlance, for each channel intensity value to represent them as precise percentages, our image would consume 64 times more space, roughly 7.4 MB! With our 3 bpp scheme, we have only 2 choices ( 1 or 0 ) for each channel of a pixel, giving us a total of 2 bpp = 2 bpc \u22c5 num channels = 2 1 \u22c5 3 = 2 3 = 8 2^{\\text {bpp}} = 2^{\\text {bpc } \\cdot \\text { num channels}} = 2^{1 \\cdot 3} = 2^{3} = 8 2 bpp = 2 bpc \u22c5 num channels = 2 1 \u22c5 3 = 2 3 = 8 unique colors. If we instead used 24 bpp, our spectrum would contain over 16 million colors, and the hypothetical 640x480 image would be approximately 921 kB. The below image simulates--by limiting the color palette--the effect various bit-per-pixel values may have on rendering a particular image. From left to right: 128 colors, 64 colors, 32 colors, and finally 16 colors.","title":"Color Representation"},{"location":"001_image_basics/about_images/#interpreting-pixel-values","text":"Although we don't represent channel intensity values directly as percentages, they are implicit fractions. Using an 8 bpc scheme, the possible intensity values are between [ 0 , 2 bpc \u2212 1 ] = [ 0 , 2 8 \u2212 1 ] = [ 0 , 255 ] \\left[0,\\ 2^{\\text {bpc}} - 1\\right] = \\left[0,\\ 2^{8} - 1\\right] = \\left[0, 255\\right] [ 0 , 2 bpc \u2212 1 ] = [ 0 , 2 8 \u2212 1 ] = [ 0 , 255 ] If our color mode is RGB, we can mentally visualize the pixel (85, 170, 255) as being [ r 2 bpc \u2212 1 , g 2 bpc \u2212 1 , b 2 bpc \u2212 1 ] = [ 85 2 8 \u2212 1 , 170 2 8 \u2212 1 , 255 2 8 \u2212 1 ] \u2248 [ 0.3 , 0.6 , 1.0 ] \\left[\\frac{r}{2^{\\text {bpc}} - 1}, \\frac{g}{2^{\\text {bpc}} - 1}, \\frac{b}{2^{\\text {bpc}} - 1}\\right] = \\left[\\frac{85}{2^{8} - 1}, \\frac{170}{2^{8} - 1}, \\frac{255}{2^{8} - 1}\\right] \\approx \\left[0.3, 0.6, 1.0\\right] [ 2 bpc \u2212 1 r \u200b , 2 bpc \u2212 1 g \u200b , 2 bpc \u2212 1 b \u200b ] = [ 2 8 \u2212 1 85 \u200b , 2 8 \u2212 1 170 \u200b , 2 8 \u2212 1 255 \u200b ] \u2248 [ 0.3 , 0.6 , 1.0 ] which is a little bit of red, a moderate ammount of green, and a lot of blue, yielding the color below. (R, G, B) Color English Name (0.3, 0.6, 1.0) Light Blue","title":"Interpreting Pixel Values"},{"location":"001_image_basics/about_images/#image-metadata","text":"If we encounter the pixel data (1, 2, 3, 4) in the wild, how do we interpret it? For example, what is this new fourth element that we haven't dealt with yet? Are the elements RGBA intensities, or maybe CMYK, or something else? The pixel data is valid using a 3 bpc / 12 bpp scheme, but does that scheme really give us the intended upper limits? The pixel is also valid (but semantically different) if interpretted using an 8 bpc / 32 bpp scheme. Image metadata answers all of these questions for us and in general teaches us how to interpret not only an image's pixel data but even other parts of its metadata. As we know, there are multiple popular image file formats (for example, bitmaps, JPEG, and PNG) in circulation today. Most image formats have their own metadata schema, and many of those schemas have multiple schema versions as a result of their filetypes evolving over the years. This alone makes parsing images nontrivial. We will experience this firsthand in the next section.","title":"Image Metadata"},{"location":"001_image_basics/parsing_image_metadata/challenge/","text":"Parsing Image Metadata \u00b6 Challenge \u00b6 Write a command-line program that takes an image file as its input and prints all parsed image metadata as output. You don't have to deal with the pixel array yet. If you'll be parsing a bitmap v4 image, use the data structure definitions in Theory (or supplemental documentation) to guide your development. Below is output from our bitmap parser ( bp.py ) program when passed our provided sample image of the Tokyo Skytree. Note that most values are printed as read out of the image file, but some values are adjusted before printing (for example that for File type ). $ ./bp.py 2021-02-22-tokyo-skytree-grayscale.bmp File type : BM Size : 263290 bytes Pixel data offset: 1146 bytes Size : 108 bytes Width : 512 px Height : 512 px Number of color planes : 1 Number of bits per pixel : 8 Compression type : 0 Pixel data size : 262144 bytes Width resolution : 11811 ppm Height resolution : 11811 ppm Number of colors used : 256 Number of colors required: 256 Red bitmask : 0x73524742 Green bitmask : 0x0 Blue bitmask : 0x0 Alpha bitmask : 0x0 Color space type : 0 Color space endpoints : red : (0.0, 0.0, 0.0) green: (0.0, 0.0, 0.0) blue : (0.0, 0.0, 3.0517578125e-05) Red gamma : 0.0 Green gamma : 0.0 Blue gamma : 0.0","title":"Challenge"},{"location":"001_image_basics/parsing_image_metadata/challenge/#parsing-image-metadata","text":"","title":"Parsing Image Metadata"},{"location":"001_image_basics/parsing_image_metadata/challenge/#challenge","text":"Write a command-line program that takes an image file as its input and prints all parsed image metadata as output. You don't have to deal with the pixel array yet. If you'll be parsing a bitmap v4 image, use the data structure definitions in Theory (or supplemental documentation) to guide your development. Below is output from our bitmap parser ( bp.py ) program when passed our provided sample image of the Tokyo Skytree. Note that most values are printed as read out of the image file, but some values are adjusted before printing (for example that for File type ). $ ./bp.py 2021-02-22-tokyo-skytree-grayscale.bmp File type : BM Size : 263290 bytes Pixel data offset: 1146 bytes Size : 108 bytes Width : 512 px Height : 512 px Number of color planes : 1 Number of bits per pixel : 8 Compression type : 0 Pixel data size : 262144 bytes Width resolution : 11811 ppm Height resolution : 11811 ppm Number of colors used : 256 Number of colors required: 256 Red bitmask : 0x73524742 Green bitmask : 0x0 Blue bitmask : 0x0 Alpha bitmask : 0x0 Color space type : 0 Color space endpoints : red : (0.0, 0.0, 0.0) green: (0.0, 0.0, 0.0) blue : (0.0, 0.0, 3.0517578125e-05) Red gamma : 0.0 Green gamma : 0.0 Blue gamma : 0.0","title":"Challenge"},{"location":"001_image_basics/parsing_image_metadata/implementation/","text":".katex img { object-fit: fill; padding: unset; display: block; position: absolute; width: 100%; height: inherit; } Parsing Image Metadata \u00b6 Implementation \u00b6 When implementing our bitmap parser, bp , let's start with basic functionality that enables us to modify our parser, run it against input, and see what changed. This way we can quickly visually debug things. main \u00b6 Our main script will be bp.py . We'll use argparse to build a CLI that takes as input a pathname to an image file. We'll open that file for reading as binary, slurp its contents, and pass them to a (currently stub) BitmapV4 class for parsing. #!/usr/bin/python3 -B import argparse class BitmapV4 : def __init__ ( self , data ): pass def main (): parser = argparse . ArgumentParser ( description = \"Limited-functionality bitmap parser\" ) parser . add_argument ( \"image\" , help = \"An image file pathname\" ) args = parser . parse_args () with open ( args . image , \"rb\" ) as f : data = f . read () image = BitmapV4 ( data ) print ( image ) if __name__ == \"__main__\" : main () At this point, you can run your program, and if your input file exists, your program will print details about your BitmapV4 instance. $ chmod +x bp.py $ ./bp.py 2021-02-22-tokyo-skytree-grayscale.bmp <__main__.BitmapV4 object at 0x7fcd816bad30> BitmapV4 \u00b6 We'll do our bitmap parsing logic in BitmapV4 and some additional classes. If this were a proper tool, we might have an Image base class with some generic properties like width , height , and pixels so that we could parse various image file types in corresponding classes but present a common API to the user through polymorphism. We won't go that far here, though. We anticipate having to parse the general bitmap file header and also the V4 header, so we create class stubs for those. In the BitmapV4 constructor, we pass the bitmap data and a corresponding byte offset to constructors of the header stubs. We define our own __str__ method which will now be used when we call print(image) as we did in main() . class BitmapFileHeader : def __init__ ( self , data , offset ): pass class V4InfoHeader : def __init__ ( self , data , offset ): pass class BitmapV4 : def __init__ ( self , data ): \"\"\" Arguments: data(bytes): The binary data of an entire bitmap image file. \"\"\" self . file_header = BitmapFileHeader ( data , 0 ) self . info_header = V4InfoHeader ( data , 14 ) def __str__ ( self ): return f \" { self . file_header } \\n { self . info_header } \" Running our program now prints something similar to $ ./bp.py 2021-02-22-tokyo-skytree-grayscale.bmp <__main__.BitmapFileHeader object at 0x7f3acd451610> <__main__.V4InfoHeader object at 0x7f3acd49a9d0> BitmapFileHeader \u00b6 Our BitmapFileHeader corresponds to the official bitmap BITMAPFILEHEADER . We use the struct module to parse the image byte array. The struct module returns tuples, and we don't want to create an intermediate data structure that essentially mirrors our class members, so we unpack the tuple in-place. Remember that bitmap data is stored unconditionally in little endian. Therefore, our struct.unpack_from format string leads with < indicating little endian. H indicates an unsigned 16-bit integer, and I indicates an unsigned 32-bit integer. We define our own __str__ method which prints information about our instance. Since the \"magic\" bytes are stored in little endian, we have to swap the two lowest bytes and then convert them to characters before printing in order to see the text \"BM.\" import struct class BitmapFileHeader : def __init__ ( self , data , offset ): \"\"\" Parse a bitmap file header from a byte array. Args: data(bytes): Binary data read from a bitmap file. offset(int): The byte offset in `data` at which parsing starts. \"\"\" self . file_type , \\ self . size_bytes , \\ self . reserved_1 , \\ self . reserved_2 , \\ self . pixel_data_offset_bytes = struct . unpack_from ( \"<HIHHI\" , data , offset = offset ) def __str__ ( self ): magic_byte_1 = chr ( self . file_type & 0xff ) magic_byte_2 = chr (( self . file_type & 0xff00 ) >> 8 ) return f \"File type : { magic_byte_1 }{ magic_byte_2 } \\n \" + \\ f \"Size : { self . size_bytes } bytes \\n \" + \\ f \"Pixel data offset: { self . pixel_data_offset_bytes } bytes\" Now our program will print something more interesting. $ ./bp 2021-02-22-tokyo-skytree-grayscale.bmp File type : BM Size : 263290 bytes Pixel data offset: 1146 bytes <__main__.V4InfoHeader object at 0x7f2d5c153a00> du confirms the file size. $ du -b ./2021-02-22-tokyo-skytree-grayscale.bmp 263290 ./2021-02-22-tokyo-skytree-grayscale.bmp V4InfoHeader \u00b6 Our V4InfoHeader corresponds to the official bitmap BITMAPV4HEADER . Parsing V4InfoHeader is a lot like parsing BitmapFileHeader except that our constructor delegates to another constructor partway through parsing. Also, some of our fields are in fixed (x.y) notation, so we need to convert them after parsing. We do this by assigning the parsed value to a temporary, dividing that temporary by 2**y , and then assigning the quotient to a member variable. Note also that we have to manually adjust offset as we parse different parts of data . class CIEXYZ : def __init__ ( self , data , offset ): pass class CIEXYZTriple : def __init__ ( self , data , offset ): pass class V4InfoHeader : def __init__ ( self , data , offset ): \"\"\" Parse a bitmap version 4 info header from a byte array. Args: data(bytes): Binary data read from a bitmap file. offset(int): The byte offset in `data` at which parsing starts. \"\"\" self . size_bytes , \\ self . width_px , \\ self . height_px , \\ self . num_color_planes , \\ self . num_bits_per_pixel , \\ self . compression_type , \\ self . pixel_data_size_bytes , \\ self . pixels_per_meter_width , \\ self . pixels_per_meter_height , \\ self . num_colors_used , \\ self . num_colors_required , \\ self . red_bitmask , \\ self . green_bitmask , \\ self . blue_bitmask , \\ self . alpha_bitmask , \\ self . color_space_type = struct . unpack_from ( \"<IiiHHIIiiIIIIIII\" , data , offset = offset ) self . color_space_endpoints = CIEXYZTriple ( data , offset + 60 ) red_gamma , \\ green_gamma , \\ blue_gamma = struct . unpack_from ( \"<III\" , data , offset = offset + 96 ) self . red_gamma = red_gamma / 2 ** 30 self . green_gamma = green_gamma / 2 ** 30 self . blue_gamma = blue_gamma / 2 ** 30 def __str__ ( self ): return \\ f \"Size : { self . size_bytes } bytes \\n \" + \\ f \"Width : { self . width_px } px \\n \" + \\ f \"Height : { self . height_px } px \\n \" + \\ f \"Number of color planes : { self . num_color_planes } \\n \" + \\ f \"Number of bits per pixel : { self . num_bits_per_pixel } \\n \" + \\ f \"Compression type : { self . compression_type } \\n \" + \\ f \"Pixel data size : { self . pixel_data_size_bytes } bytes \\n \" + \\ f \"Width resolution : { self . pixels_per_meter_width } ppm \\n \" + \\ f \"Height resolution : { self . pixels_per_meter_height } ppm \\n \" + \\ f \"Number of colors used : { self . num_colors_used } \\n \" + \\ f \"Number of colors required: { self . num_colors_required } \\n \" + \\ f \"Red bitmask : 0x { self . red_bitmask : X } \\n \" + \\ f \"Green bitmask : 0x { self . green_bitmask : X } \\n \" + \\ f \"Blue bitmask : 0x { self . blue_bitmask : X } \\n \" + \\ f \"Alpha bitmask : 0x { self . alpha_bitmask : X } \\n \" + \\ f \"Color space type : { self . color_space_type } \\n \" + \\ f \"Color space endpoints : \\n { self . color_space_endpoints } \\n \" + \\ f \"Red gamma : { self . red_gamma } \\n \" + \\ f \"Green gamma : { self . green_gamma } \\n \" + \\ f \"Blue gamma : { self . blue_gamma } \" We can run our program again and see additional, interesting output. $ ./bp 2021-02-22-tokyo-skytree-grayscale.bmp File type : BM Size : 263290 bytes Pixel data offset: 1146 bytes Size : 108 bytes Width : 512 px Height : 512 px Number of color planes : 1 Number of bits per pixel : 8 Compression type : 0 Pixel data size : 262144 bytes Width resolution : 11811 ppm Height resolution : 11811 ppm Number of colors used : 256 Number of colors required: 256 Red bitmask : 0x73524742 Green bitmask : 0x0 Blue bitmask : 0x0 Alpha bitmask : 0x0 Color space type : 0 Color space endpoints : <__main__.CIEXYZTriple object at 0x7fa28c7c5100> Red gamma : 0.0 Green gamma : 0.0 Blue gamma : 0.0 Let's confirm the output. Using an image viewer, we can confirm that our input image is indeed 512x512 pixels, so the height and width are okay. From the documentation, we expect the number of color planes to be 1, so that is also okay. As for bits per pixel, since our image is grayscale, each pixel is encoded as a single intensity value of black (that is, we have only one \"color\" channel). If there are 8 bits per pixel, the possible pixel values are [0, 255]. Other image properties agree with our 8 bpp report, too. For example, the number of colors used and the number of colors required. But even more telling is the pixel data size. pixel data size = width \u22c5 height \u22c5 num channels \u22c5 bytes per pixel = 512 \u22c5 512 \u22c5 1 \u22c5 1 = 262144 \\begin{align} \\text {pixel data size} &= \\text {width} \\cdot \\text {height} \\cdot \\text {num channels} \\cdot \\text {bytes per pixel} \\\\ & = 512 \\cdot 512 \\cdot 1 \\cdot 1 \\\\ & = 262144 \\end{align} pixel data size \u200b = width \u22c5 height \u22c5 num channels \u22c5 bytes per pixel = 512 \u22c5 512 \u22c5 1 \u22c5 1 = 262144 \u200b \u200b Note that in (1) above we are concerned with bytes per pixel. We see that our pixel data size agrees with our other measurements! With confidence in our pixel data size, we can now confirm our file header's pixel data offset. If we add the pixel data size to the data offset, we should get the total file size. file size = pixel data offset + pixel data size = 1146 + 262144 = 263290 \\begin{align} \\text {file size} &= \\text {pixel data offset} + \\text {pixel data size} \\\\ &= 1146 + 262144 \\\\ &= 263290 \\end{align} file size \u200b = pixel data offset + pixel data size = 1146 + 262144 = 263290 \u200b \u200b which does indeed agree with the file size reported internally (in the size field in the file header) and externally using tools like du . We ignore the width and height resolution as they're not important to our learning here. Do note the red bitmask, though. It is non-zero, but does it matter? The answer is no, according to the bitmap documentation. Our compression type is 0, indicating an uncompressed format that disregards the RGB bitmasks. That the red bitmask is non-zero here seems to be an artifact from GIMP (in the case of our sample image), but it is of no other concern to us. We are okay with the RGB gamma values being 0 because our image is grayscale. CIEXYZ and CIEXYZTriple \u00b6 CIEXYZ and CIEXYZTriple correspond to the official bitmap CIEXYZ and CIEXYZTRIPLE data structures. Parsing these is straightforward by now and uses no techniques we haven't seen already. class CIEXYZ : def __init__ ( self , data , offset ): \"\"\" Parse a color endpoint from a byte array. Arguments: data(bytes): Binary data read from a bitmap file. offset(int): The byte offset in `data` at which parsing starts. \"\"\" x , \\ y , \\ z = struct . unpack_from ( \"<III\" , data , offset = offset ) self . x = x / 2 ** 16 self . y = y / 2 ** 16 self . z = z / 2 ** 16 def __str__ ( self ): return f \"( { self . x } , { self . y } , { self . z } )\" class CIEXYZTriple : def __init__ ( self , data , offset ): \"\"\" Parse color endpoints in a color space from a byte array. Arguments: data(bytes): Binary data read from a bitmap file. offset(int): The byte offset in `data` at which parsing starts. \"\"\" self . red = CIEXYZ ( data , offset ) self . green = CIEXYZ ( data , offset + 12 ) self . blue = CIEXYZ ( data , offset + 24 ) def __str__ ( self ): return f \"red : { self . red } \\n \" + \\ f \"green: { self . green } \\n \" + \\ f \"blue : { self . blue } \" If we run our program against our image again, we see $ ./bp 2021-02-22-tokyo-skytree-grayscale.bmp File type : BM Size : 263290 bytes Pixel data offset: 1146 bytes Size : 108 bytes Width : 512 px Height : 512 px Number of color planes : 1 Number of bits per pixel : 8 Compression type : 0 Pixel data size : 262144 bytes Width resolution : 11811 ppm Height resolution : 11811 ppm Number of colors used : 256 Number of colors required: 256 Red bitmask : 0x73524742 Green bitmask : 0x0 Blue bitmask : 0x0 Alpha bitmask : 0x0 Color space type : 0 Color space endpoints : red : (0.0, 0.0, 0.0) green: (0.0, 0.0, 0.0) blue : (0.0, 0.0, 3.0517578125e-05) Red gamma : 0.0 Green gamma : 0.0 Blue gamma : 0.0 The new information here is that of the color space endpoints. All values are 0 except the last element of the blue endpoint (which is still very close to 0 in this case). Unlike the value for the red bitmask which the documentation suggested we can ignore, our color space type is 0 here indicating (again, from the documentation) that we must take the color endpoints into consideration. However, these are endpoints for an RGB color space, but we know that our image is grayscale, so we can actually disregard these values. The non-zero element in the blue endpoint seems to again be an artifact of GIMP. Conclusion \u00b6 This concludes our work for parsing metadata for a bitmap v4 image. Take a moment to consider the many image file formats in existence today, and also think about the many image formats your operating system can render for you with only a few clicks or keystrokes! It's nice to not have to deal with this kind of boilerplate work. In the future, we will use libraries to handle all of this parsing for us. We're not quite there yet, though. In the next section, we'll parse the pixel data out of our test image by hand.","title":"Implementation"},{"location":"001_image_basics/parsing_image_metadata/implementation/#parsing-image-metadata","text":"","title":"Parsing Image Metadata"},{"location":"001_image_basics/parsing_image_metadata/implementation/#implementation","text":"When implementing our bitmap parser, bp , let's start with basic functionality that enables us to modify our parser, run it against input, and see what changed. This way we can quickly visually debug things.","title":"Implementation"},{"location":"001_image_basics/parsing_image_metadata/implementation/#main","text":"Our main script will be bp.py . We'll use argparse to build a CLI that takes as input a pathname to an image file. We'll open that file for reading as binary, slurp its contents, and pass them to a (currently stub) BitmapV4 class for parsing. #!/usr/bin/python3 -B import argparse class BitmapV4 : def __init__ ( self , data ): pass def main (): parser = argparse . ArgumentParser ( description = \"Limited-functionality bitmap parser\" ) parser . add_argument ( \"image\" , help = \"An image file pathname\" ) args = parser . parse_args () with open ( args . image , \"rb\" ) as f : data = f . read () image = BitmapV4 ( data ) print ( image ) if __name__ == \"__main__\" : main () At this point, you can run your program, and if your input file exists, your program will print details about your BitmapV4 instance. $ chmod +x bp.py $ ./bp.py 2021-02-22-tokyo-skytree-grayscale.bmp <__main__.BitmapV4 object at 0x7fcd816bad30>","title":"main"},{"location":"001_image_basics/parsing_image_metadata/implementation/#bitmapv4","text":"We'll do our bitmap parsing logic in BitmapV4 and some additional classes. If this were a proper tool, we might have an Image base class with some generic properties like width , height , and pixels so that we could parse various image file types in corresponding classes but present a common API to the user through polymorphism. We won't go that far here, though. We anticipate having to parse the general bitmap file header and also the V4 header, so we create class stubs for those. In the BitmapV4 constructor, we pass the bitmap data and a corresponding byte offset to constructors of the header stubs. We define our own __str__ method which will now be used when we call print(image) as we did in main() . class BitmapFileHeader : def __init__ ( self , data , offset ): pass class V4InfoHeader : def __init__ ( self , data , offset ): pass class BitmapV4 : def __init__ ( self , data ): \"\"\" Arguments: data(bytes): The binary data of an entire bitmap image file. \"\"\" self . file_header = BitmapFileHeader ( data , 0 ) self . info_header = V4InfoHeader ( data , 14 ) def __str__ ( self ): return f \" { self . file_header } \\n { self . info_header } \" Running our program now prints something similar to $ ./bp.py 2021-02-22-tokyo-skytree-grayscale.bmp <__main__.BitmapFileHeader object at 0x7f3acd451610> <__main__.V4InfoHeader object at 0x7f3acd49a9d0>","title":"BitmapV4"},{"location":"001_image_basics/parsing_image_metadata/implementation/#bitmapfileheader","text":"Our BitmapFileHeader corresponds to the official bitmap BITMAPFILEHEADER . We use the struct module to parse the image byte array. The struct module returns tuples, and we don't want to create an intermediate data structure that essentially mirrors our class members, so we unpack the tuple in-place. Remember that bitmap data is stored unconditionally in little endian. Therefore, our struct.unpack_from format string leads with < indicating little endian. H indicates an unsigned 16-bit integer, and I indicates an unsigned 32-bit integer. We define our own __str__ method which prints information about our instance. Since the \"magic\" bytes are stored in little endian, we have to swap the two lowest bytes and then convert them to characters before printing in order to see the text \"BM.\" import struct class BitmapFileHeader : def __init__ ( self , data , offset ): \"\"\" Parse a bitmap file header from a byte array. Args: data(bytes): Binary data read from a bitmap file. offset(int): The byte offset in `data` at which parsing starts. \"\"\" self . file_type , \\ self . size_bytes , \\ self . reserved_1 , \\ self . reserved_2 , \\ self . pixel_data_offset_bytes = struct . unpack_from ( \"<HIHHI\" , data , offset = offset ) def __str__ ( self ): magic_byte_1 = chr ( self . file_type & 0xff ) magic_byte_2 = chr (( self . file_type & 0xff00 ) >> 8 ) return f \"File type : { magic_byte_1 }{ magic_byte_2 } \\n \" + \\ f \"Size : { self . size_bytes } bytes \\n \" + \\ f \"Pixel data offset: { self . pixel_data_offset_bytes } bytes\" Now our program will print something more interesting. $ ./bp 2021-02-22-tokyo-skytree-grayscale.bmp File type : BM Size : 263290 bytes Pixel data offset: 1146 bytes <__main__.V4InfoHeader object at 0x7f2d5c153a00> du confirms the file size. $ du -b ./2021-02-22-tokyo-skytree-grayscale.bmp 263290 ./2021-02-22-tokyo-skytree-grayscale.bmp","title":"BitmapFileHeader"},{"location":"001_image_basics/parsing_image_metadata/implementation/#v4infoheader","text":"Our V4InfoHeader corresponds to the official bitmap BITMAPV4HEADER . Parsing V4InfoHeader is a lot like parsing BitmapFileHeader except that our constructor delegates to another constructor partway through parsing. Also, some of our fields are in fixed (x.y) notation, so we need to convert them after parsing. We do this by assigning the parsed value to a temporary, dividing that temporary by 2**y , and then assigning the quotient to a member variable. Note also that we have to manually adjust offset as we parse different parts of data . class CIEXYZ : def __init__ ( self , data , offset ): pass class CIEXYZTriple : def __init__ ( self , data , offset ): pass class V4InfoHeader : def __init__ ( self , data , offset ): \"\"\" Parse a bitmap version 4 info header from a byte array. Args: data(bytes): Binary data read from a bitmap file. offset(int): The byte offset in `data` at which parsing starts. \"\"\" self . size_bytes , \\ self . width_px , \\ self . height_px , \\ self . num_color_planes , \\ self . num_bits_per_pixel , \\ self . compression_type , \\ self . pixel_data_size_bytes , \\ self . pixels_per_meter_width , \\ self . pixels_per_meter_height , \\ self . num_colors_used , \\ self . num_colors_required , \\ self . red_bitmask , \\ self . green_bitmask , \\ self . blue_bitmask , \\ self . alpha_bitmask , \\ self . color_space_type = struct . unpack_from ( \"<IiiHHIIiiIIIIIII\" , data , offset = offset ) self . color_space_endpoints = CIEXYZTriple ( data , offset + 60 ) red_gamma , \\ green_gamma , \\ blue_gamma = struct . unpack_from ( \"<III\" , data , offset = offset + 96 ) self . red_gamma = red_gamma / 2 ** 30 self . green_gamma = green_gamma / 2 ** 30 self . blue_gamma = blue_gamma / 2 ** 30 def __str__ ( self ): return \\ f \"Size : { self . size_bytes } bytes \\n \" + \\ f \"Width : { self . width_px } px \\n \" + \\ f \"Height : { self . height_px } px \\n \" + \\ f \"Number of color planes : { self . num_color_planes } \\n \" + \\ f \"Number of bits per pixel : { self . num_bits_per_pixel } \\n \" + \\ f \"Compression type : { self . compression_type } \\n \" + \\ f \"Pixel data size : { self . pixel_data_size_bytes } bytes \\n \" + \\ f \"Width resolution : { self . pixels_per_meter_width } ppm \\n \" + \\ f \"Height resolution : { self . pixels_per_meter_height } ppm \\n \" + \\ f \"Number of colors used : { self . num_colors_used } \\n \" + \\ f \"Number of colors required: { self . num_colors_required } \\n \" + \\ f \"Red bitmask : 0x { self . red_bitmask : X } \\n \" + \\ f \"Green bitmask : 0x { self . green_bitmask : X } \\n \" + \\ f \"Blue bitmask : 0x { self . blue_bitmask : X } \\n \" + \\ f \"Alpha bitmask : 0x { self . alpha_bitmask : X } \\n \" + \\ f \"Color space type : { self . color_space_type } \\n \" + \\ f \"Color space endpoints : \\n { self . color_space_endpoints } \\n \" + \\ f \"Red gamma : { self . red_gamma } \\n \" + \\ f \"Green gamma : { self . green_gamma } \\n \" + \\ f \"Blue gamma : { self . blue_gamma } \" We can run our program again and see additional, interesting output. $ ./bp 2021-02-22-tokyo-skytree-grayscale.bmp File type : BM Size : 263290 bytes Pixel data offset: 1146 bytes Size : 108 bytes Width : 512 px Height : 512 px Number of color planes : 1 Number of bits per pixel : 8 Compression type : 0 Pixel data size : 262144 bytes Width resolution : 11811 ppm Height resolution : 11811 ppm Number of colors used : 256 Number of colors required: 256 Red bitmask : 0x73524742 Green bitmask : 0x0 Blue bitmask : 0x0 Alpha bitmask : 0x0 Color space type : 0 Color space endpoints : <__main__.CIEXYZTriple object at 0x7fa28c7c5100> Red gamma : 0.0 Green gamma : 0.0 Blue gamma : 0.0 Let's confirm the output. Using an image viewer, we can confirm that our input image is indeed 512x512 pixels, so the height and width are okay. From the documentation, we expect the number of color planes to be 1, so that is also okay. As for bits per pixel, since our image is grayscale, each pixel is encoded as a single intensity value of black (that is, we have only one \"color\" channel). If there are 8 bits per pixel, the possible pixel values are [0, 255]. Other image properties agree with our 8 bpp report, too. For example, the number of colors used and the number of colors required. But even more telling is the pixel data size. pixel data size = width \u22c5 height \u22c5 num channels \u22c5 bytes per pixel = 512 \u22c5 512 \u22c5 1 \u22c5 1 = 262144 \\begin{align} \\text {pixel data size} &= \\text {width} \\cdot \\text {height} \\cdot \\text {num channels} \\cdot \\text {bytes per pixel} \\\\ & = 512 \\cdot 512 \\cdot 1 \\cdot 1 \\\\ & = 262144 \\end{align} pixel data size \u200b = width \u22c5 height \u22c5 num channels \u22c5 bytes per pixel = 512 \u22c5 512 \u22c5 1 \u22c5 1 = 262144 \u200b \u200b Note that in (1) above we are concerned with bytes per pixel. We see that our pixel data size agrees with our other measurements! With confidence in our pixel data size, we can now confirm our file header's pixel data offset. If we add the pixel data size to the data offset, we should get the total file size. file size = pixel data offset + pixel data size = 1146 + 262144 = 263290 \\begin{align} \\text {file size} &= \\text {pixel data offset} + \\text {pixel data size} \\\\ &= 1146 + 262144 \\\\ &= 263290 \\end{align} file size \u200b = pixel data offset + pixel data size = 1146 + 262144 = 263290 \u200b \u200b which does indeed agree with the file size reported internally (in the size field in the file header) and externally using tools like du . We ignore the width and height resolution as they're not important to our learning here. Do note the red bitmask, though. It is non-zero, but does it matter? The answer is no, according to the bitmap documentation. Our compression type is 0, indicating an uncompressed format that disregards the RGB bitmasks. That the red bitmask is non-zero here seems to be an artifact from GIMP (in the case of our sample image), but it is of no other concern to us. We are okay with the RGB gamma values being 0 because our image is grayscale.","title":"V4InfoHeader"},{"location":"001_image_basics/parsing_image_metadata/implementation/#ciexyz-and-ciexyztriple","text":"CIEXYZ and CIEXYZTriple correspond to the official bitmap CIEXYZ and CIEXYZTRIPLE data structures. Parsing these is straightforward by now and uses no techniques we haven't seen already. class CIEXYZ : def __init__ ( self , data , offset ): \"\"\" Parse a color endpoint from a byte array. Arguments: data(bytes): Binary data read from a bitmap file. offset(int): The byte offset in `data` at which parsing starts. \"\"\" x , \\ y , \\ z = struct . unpack_from ( \"<III\" , data , offset = offset ) self . x = x / 2 ** 16 self . y = y / 2 ** 16 self . z = z / 2 ** 16 def __str__ ( self ): return f \"( { self . x } , { self . y } , { self . z } )\" class CIEXYZTriple : def __init__ ( self , data , offset ): \"\"\" Parse color endpoints in a color space from a byte array. Arguments: data(bytes): Binary data read from a bitmap file. offset(int): The byte offset in `data` at which parsing starts. \"\"\" self . red = CIEXYZ ( data , offset ) self . green = CIEXYZ ( data , offset + 12 ) self . blue = CIEXYZ ( data , offset + 24 ) def __str__ ( self ): return f \"red : { self . red } \\n \" + \\ f \"green: { self . green } \\n \" + \\ f \"blue : { self . blue } \" If we run our program against our image again, we see $ ./bp 2021-02-22-tokyo-skytree-grayscale.bmp File type : BM Size : 263290 bytes Pixel data offset: 1146 bytes Size : 108 bytes Width : 512 px Height : 512 px Number of color planes : 1 Number of bits per pixel : 8 Compression type : 0 Pixel data size : 262144 bytes Width resolution : 11811 ppm Height resolution : 11811 ppm Number of colors used : 256 Number of colors required: 256 Red bitmask : 0x73524742 Green bitmask : 0x0 Blue bitmask : 0x0 Alpha bitmask : 0x0 Color space type : 0 Color space endpoints : red : (0.0, 0.0, 0.0) green: (0.0, 0.0, 0.0) blue : (0.0, 0.0, 3.0517578125e-05) Red gamma : 0.0 Green gamma : 0.0 Blue gamma : 0.0 The new information here is that of the color space endpoints. All values are 0 except the last element of the blue endpoint (which is still very close to 0 in this case). Unlike the value for the red bitmask which the documentation suggested we can ignore, our color space type is 0 here indicating (again, from the documentation) that we must take the color endpoints into consideration. However, these are endpoints for an RGB color space, but we know that our image is grayscale, so we can actually disregard these values. The non-zero element in the blue endpoint seems to again be an artifact of GIMP.","title":"CIEXYZ and CIEXYZTriple"},{"location":"001_image_basics/parsing_image_metadata/implementation/#conclusion","text":"This concludes our work for parsing metadata for a bitmap v4 image. Take a moment to consider the many image file formats in existence today, and also think about the many image formats your operating system can render for you with only a few clicks or keystrokes! It's nice to not have to deal with this kind of boilerplate work. In the future, we will use libraries to handle all of this parsing for us. We're not quite there yet, though. In the next section, we'll parse the pixel data out of our test image by hand.","title":"Conclusion"},{"location":"001_image_basics/parsing_image_metadata/theory/","text":"Parsing Image Metadata \u00b6 Theory \u00b6 Before we use handy libraries to parse images for us, we're going to write our own limited-functionality parser to get an idea of what these parsing libraries do for us behind the scenes. Preparing An Image \u00b6 For this exercise, we'll be working with a bitmap image. If you want to generate your own and follow our example code, it must: be version 4 be grayscale have a width evenly divisible by 4 Our example code will only correctly parse images which conform to the above. We'll explain why later. GIMP 2.10 can produce conformant bitmap images easily. If you don't want to create your own image, you can use the image we have prepared here, one of the Tokyo Skytree . We will test against our prepared image. Why Bitmap? \u00b6 While we want to understand the deeper intricacies of image parsing, we also don't want to spend too much time on it. Parsing compressed JPEG or PNG files by hand requires more effort than parsing an uncompressed bitmap image. On the other end of the spectrum are filetypes such as PPM which are too trivial to be useful parsing examples. We pick bitmaps as a comfortable medium. If you want to challenge yourself with more sophisticated image file types, we encourage you. Bitmaps \u00b6 The bitmap file format was developed by Microsoft. The file format evolved over time, so while a file's extension may be \".bmp,\" the file data may be stored in one of at least 5 different ways. We determine a bitmap file's version while we are parsing it. In this exercise, we use bitmap version 4 simply because that's the version that modern image processing tools such as GIMP output by default for images with properties similar to that of our test image. For reference and convenience, we detail the relevant parts of the bitmap version 4 data structure in this text. For complete documentation, see Microsoft's own documentation or that elsewhere online. Bitmap Version 4 Layout \u00b6 Entity Size (bytes) Byte offset (decimal) BITMAPFILEHEADER 14 0 BITMAPV4HEADER 108 14 Below we detail these types in C++ to show the byte mapping. Note that all data in a bitmap file is stored in little endian. BITMAPFILEHEADER \u00b6 The bitmap file header is common to all bitmaps. It provides basic file metadata. struct BITMAPFILEHEADER { // \"Magic\" bytes that indicate the file type. Should be ASCII \"BM\" in our case. uint16_t file_type ; // The size in bytes of the entire bitmap file. uint32_t size_bytes ; // Don't care. uint16_t reserved_1 ; // Don't care. uint16_t reserved_2 ; // The offset in bytes from the beginning of the file to the pixel data. uint32_t pixel_data_offset_bytes ; }; BITMAPV4HEADER \u00b6 The bitmap v4 header is a bitmap-version-specific data structure. When parsing bitmap images, we determine which version-specific data structure to use by parsing the first 4 bytes after the bitmap file header (in other words, the 4 bytes starting at absolute offset 14). These bytes correspond to the header_size_bytes field below and indicate the byte size of the containing version-specific header object. Version 4 requires a byte size of exactly 108. Note the documentation for pixel_data_size_bytes . It is why we are working with an image with a width evenly divisible by 4 (to make things easier for us in later parsing). Some fields below represent integers in a fixed x.y notation (ex: 2.30). This means that the first x bits are the whole-number bits and the remaining y bits are the fractional bits. struct BITMAPV4HEADER { // The size in bytes of this header; must be 108 for a V4 header. uint32_t header_size_bytes ; // The width in pixels of the image. int32_t width_px ; // The height in pixels of the image. If the height is positive, the image is // a bottom-up one with an origin at the lower-left corner. If the height is // negative, the image is a top-down one with its origin at the top-left // corner. int32_t height_px ; // The number of color planes in the image; must be 1. uint16_t num_color_planes ; uint16_t num_bits_per_pixel ; // The compression type used in a compressed, bottom-up image. uint32_t compression_type ; // The size in bytes of the pixel data array, including any padding. Rows are // always padded to a size evenly divisible by 4 so that each row can be // encoded as a fixed number of 32-bit integers. uint32_t pixel_data_size_bytes ; // The horizontal resolution in pixels-per-meter. int32_t pixels_per_meter_width ; // The vertical resolution in pixels-per-meter. int32_t pixels_per_meter_height ; // The number of color indices actually used in the color table. 0 indicates // all colors are used; uint32_t num_colors_used ; // The number of colors required to render the image. 0 indicates all colors // are required. uint32_t num_colors_required ; // A bitmask for extracting the red channel from pixel data. uint32_t red_bitmask ; // A bitmask for extracting the green channel from pixel data. uint32_t green_bitmask ; // A bitmask for extracting the blue channel from pixel data. uint32_t blue bitmask ; // A bitmask for extracting the alpha channel from pixel data. uint32_t alpha_bitmask ; // The color space type; must be LCS_CALIBRATED_RGB (0x0). // See: https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-wmf/eb4bbd50-b3ce-4917-895c-be31f214797f uint32_t color_space_type ; CIEXYZTRIPLE color_space_endpoints ; // Tone response curve for red in 16.16 format. uint32_t red_gamma ; // Tone response curve for green in 16.16 format. uint32_t green_gamma ; // Tone response curve for blue in 16.16 format. uint32_t blue_gamma ; }; // Contains the endpoints in a color space. // See: https://docs.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-ciexyztriple struct CIEXYZTRIPLE { CIEXYZ red ; CIEXYZ green ; CIEXYZ blue ; }; // The components of a color in a color space. The fields are in 2.30 form. // See: https://docs.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-ciexyz struct CIEXYZ { uint32_t x ; uint32_t y ; uint32_t z ; };","title":"Theory"},{"location":"001_image_basics/parsing_image_metadata/theory/#parsing-image-metadata","text":"","title":"Parsing Image Metadata"},{"location":"001_image_basics/parsing_image_metadata/theory/#theory","text":"Before we use handy libraries to parse images for us, we're going to write our own limited-functionality parser to get an idea of what these parsing libraries do for us behind the scenes.","title":"Theory"},{"location":"001_image_basics/parsing_image_metadata/theory/#preparing-an-image","text":"For this exercise, we'll be working with a bitmap image. If you want to generate your own and follow our example code, it must: be version 4 be grayscale have a width evenly divisible by 4 Our example code will only correctly parse images which conform to the above. We'll explain why later. GIMP 2.10 can produce conformant bitmap images easily. If you don't want to create your own image, you can use the image we have prepared here, one of the Tokyo Skytree . We will test against our prepared image.","title":"Preparing An Image"},{"location":"001_image_basics/parsing_image_metadata/theory/#why-bitmap","text":"While we want to understand the deeper intricacies of image parsing, we also don't want to spend too much time on it. Parsing compressed JPEG or PNG files by hand requires more effort than parsing an uncompressed bitmap image. On the other end of the spectrum are filetypes such as PPM which are too trivial to be useful parsing examples. We pick bitmaps as a comfortable medium. If you want to challenge yourself with more sophisticated image file types, we encourage you.","title":"Why Bitmap?"},{"location":"001_image_basics/parsing_image_metadata/theory/#bitmaps","text":"The bitmap file format was developed by Microsoft. The file format evolved over time, so while a file's extension may be \".bmp,\" the file data may be stored in one of at least 5 different ways. We determine a bitmap file's version while we are parsing it. In this exercise, we use bitmap version 4 simply because that's the version that modern image processing tools such as GIMP output by default for images with properties similar to that of our test image. For reference and convenience, we detail the relevant parts of the bitmap version 4 data structure in this text. For complete documentation, see Microsoft's own documentation or that elsewhere online.","title":"Bitmaps"},{"location":"001_image_basics/parsing_image_metadata/theory/#bitmap-version-4-layout","text":"Entity Size (bytes) Byte offset (decimal) BITMAPFILEHEADER 14 0 BITMAPV4HEADER 108 14 Below we detail these types in C++ to show the byte mapping. Note that all data in a bitmap file is stored in little endian.","title":"Bitmap Version 4 Layout"},{"location":"001_image_basics/parsing_image_metadata/theory/#bitmapfileheader","text":"The bitmap file header is common to all bitmaps. It provides basic file metadata. struct BITMAPFILEHEADER { // \"Magic\" bytes that indicate the file type. Should be ASCII \"BM\" in our case. uint16_t file_type ; // The size in bytes of the entire bitmap file. uint32_t size_bytes ; // Don't care. uint16_t reserved_1 ; // Don't care. uint16_t reserved_2 ; // The offset in bytes from the beginning of the file to the pixel data. uint32_t pixel_data_offset_bytes ; };","title":"BITMAPFILEHEADER"},{"location":"001_image_basics/parsing_image_metadata/theory/#bitmapv4header","text":"The bitmap v4 header is a bitmap-version-specific data structure. When parsing bitmap images, we determine which version-specific data structure to use by parsing the first 4 bytes after the bitmap file header (in other words, the 4 bytes starting at absolute offset 14). These bytes correspond to the header_size_bytes field below and indicate the byte size of the containing version-specific header object. Version 4 requires a byte size of exactly 108. Note the documentation for pixel_data_size_bytes . It is why we are working with an image with a width evenly divisible by 4 (to make things easier for us in later parsing). Some fields below represent integers in a fixed x.y notation (ex: 2.30). This means that the first x bits are the whole-number bits and the remaining y bits are the fractional bits. struct BITMAPV4HEADER { // The size in bytes of this header; must be 108 for a V4 header. uint32_t header_size_bytes ; // The width in pixels of the image. int32_t width_px ; // The height in pixels of the image. If the height is positive, the image is // a bottom-up one with an origin at the lower-left corner. If the height is // negative, the image is a top-down one with its origin at the top-left // corner. int32_t height_px ; // The number of color planes in the image; must be 1. uint16_t num_color_planes ; uint16_t num_bits_per_pixel ; // The compression type used in a compressed, bottom-up image. uint32_t compression_type ; // The size in bytes of the pixel data array, including any padding. Rows are // always padded to a size evenly divisible by 4 so that each row can be // encoded as a fixed number of 32-bit integers. uint32_t pixel_data_size_bytes ; // The horizontal resolution in pixels-per-meter. int32_t pixels_per_meter_width ; // The vertical resolution in pixels-per-meter. int32_t pixels_per_meter_height ; // The number of color indices actually used in the color table. 0 indicates // all colors are used; uint32_t num_colors_used ; // The number of colors required to render the image. 0 indicates all colors // are required. uint32_t num_colors_required ; // A bitmask for extracting the red channel from pixel data. uint32_t red_bitmask ; // A bitmask for extracting the green channel from pixel data. uint32_t green_bitmask ; // A bitmask for extracting the blue channel from pixel data. uint32_t blue bitmask ; // A bitmask for extracting the alpha channel from pixel data. uint32_t alpha_bitmask ; // The color space type; must be LCS_CALIBRATED_RGB (0x0). // See: https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-wmf/eb4bbd50-b3ce-4917-895c-be31f214797f uint32_t color_space_type ; CIEXYZTRIPLE color_space_endpoints ; // Tone response curve for red in 16.16 format. uint32_t red_gamma ; // Tone response curve for green in 16.16 format. uint32_t green_gamma ; // Tone response curve for blue in 16.16 format. uint32_t blue_gamma ; }; // Contains the endpoints in a color space. // See: https://docs.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-ciexyztriple struct CIEXYZTRIPLE { CIEXYZ red ; CIEXYZ green ; CIEXYZ blue ; }; // The components of a color in a color space. The fields are in 2.30 form. // See: https://docs.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-ciexyz struct CIEXYZ { uint32_t x ; uint32_t y ; uint32_t z ; };","title":"BITMAPV4HEADER"},{"location":"001_image_basics/parsing_pixel_data/challenge/","text":"Parsing Pixel Data \u00b6 Challenge \u00b6 If you're following along using our prepared grayscale bitmap v4 image or one with identical properties to it, parsing pixel data is not much of a challenge. Instead, let's consider how we can confirm that we parsed the pixel values correctly. There are many ways to do this. Perhaps the most convenient and entertaining for us is to render an image created from our parsed pixel data. We can't simply write the bitmap file bytes back out to a bitmap file, though, as we know it would be bit-identical to our input file and therefore a moot test. First, parse the pixel data out of the image file and store it in your image abstraction you created previously. Next, create a new image based on your pixel data and render that to visually confirm you've parsed the pixel data correctly. To create a new image, you can use libraries like OpenCV or Pillow if you are already familiar with them. If you are not, no need to go out of your way to learn them at this time. We will deal with at least OpenCV later. In our implementation, we will create a new image manually using a very simple image file format: the Portable GrayMap (PGM). PGM Primer \u00b6 You can easily find information on the PGM format on sites like Wikipedia. Our description here, though, is all you need should you choose to create a PGM image. A PGM file encodes a grayscale image as ASCII in a text file. The file has two sections: the header and the pixel data. The file extension is .pgm . PGM Header \u00b6 The PGM header is as follows: P2 WIDTH HEIGHT MAX_VALUE P2 is the PGM file format identifier and must be specified verbatim. (PGM is part of a broader family of formats called the Portable Anymap Format (PNM).) WIDTH and HEIGHT are both positive integers specifying the corresponding dimension of the image in pixels. Finally, MAX_VALUE is the maximum value of any given pixel. If less than 256, each pixel is encoded in 1 byte. If 256 or greater, each pixel is encoded in 2 bytes (for a maximum value of 65,535). PGM Pixel Data \u00b6 Pixel data follows the header. Pixel data is encoded simply as the unsigned integer value (in ASCII) of each pixel. You can encode one or more pixels on each line, but we recommend you keep lines short because we know of no guarantee that lines can be of arbitrary length. Black is encoded as 0 , and white is the user-specified maximum value. Any other value is a blend between black and white. Note that the PGM file does not specify how to blend the colors, so various software may render a PGM image slightly differently. Example \u00b6 Consider a square image 2 pixels by 2 pixels. The top left pixel is black, the top right and bottom left pixels are gray, and the bottom right pixel is white. Such an image may be encoded as a PGM as follows. ( # starts a comment in PGM files.) # image.pgm # This is the header. P2 2 2 255 # And these are our 4 pixel values. 0 127 127 255 Bitmap Hint \u00b6 Recall the documentation of the height_px field of the bitmap V4 header. Pixel data in a bitmap is stored in one of two ways, depending on the sign of this field.","title":"Challenge"},{"location":"001_image_basics/parsing_pixel_data/challenge/#parsing-pixel-data","text":"","title":"Parsing Pixel Data"},{"location":"001_image_basics/parsing_pixel_data/challenge/#challenge","text":"If you're following along using our prepared grayscale bitmap v4 image or one with identical properties to it, parsing pixel data is not much of a challenge. Instead, let's consider how we can confirm that we parsed the pixel values correctly. There are many ways to do this. Perhaps the most convenient and entertaining for us is to render an image created from our parsed pixel data. We can't simply write the bitmap file bytes back out to a bitmap file, though, as we know it would be bit-identical to our input file and therefore a moot test. First, parse the pixel data out of the image file and store it in your image abstraction you created previously. Next, create a new image based on your pixel data and render that to visually confirm you've parsed the pixel data correctly. To create a new image, you can use libraries like OpenCV or Pillow if you are already familiar with them. If you are not, no need to go out of your way to learn them at this time. We will deal with at least OpenCV later. In our implementation, we will create a new image manually using a very simple image file format: the Portable GrayMap (PGM).","title":"Challenge"},{"location":"001_image_basics/parsing_pixel_data/challenge/#pgm-primer","text":"You can easily find information on the PGM format on sites like Wikipedia. Our description here, though, is all you need should you choose to create a PGM image. A PGM file encodes a grayscale image as ASCII in a text file. The file has two sections: the header and the pixel data. The file extension is .pgm .","title":"PGM Primer"},{"location":"001_image_basics/parsing_pixel_data/challenge/#pgm-header","text":"The PGM header is as follows: P2 WIDTH HEIGHT MAX_VALUE P2 is the PGM file format identifier and must be specified verbatim. (PGM is part of a broader family of formats called the Portable Anymap Format (PNM).) WIDTH and HEIGHT are both positive integers specifying the corresponding dimension of the image in pixels. Finally, MAX_VALUE is the maximum value of any given pixel. If less than 256, each pixel is encoded in 1 byte. If 256 or greater, each pixel is encoded in 2 bytes (for a maximum value of 65,535).","title":"PGM Header"},{"location":"001_image_basics/parsing_pixel_data/challenge/#pgm-pixel-data","text":"Pixel data follows the header. Pixel data is encoded simply as the unsigned integer value (in ASCII) of each pixel. You can encode one or more pixels on each line, but we recommend you keep lines short because we know of no guarantee that lines can be of arbitrary length. Black is encoded as 0 , and white is the user-specified maximum value. Any other value is a blend between black and white. Note that the PGM file does not specify how to blend the colors, so various software may render a PGM image slightly differently.","title":"PGM Pixel Data"},{"location":"001_image_basics/parsing_pixel_data/challenge/#example","text":"Consider a square image 2 pixels by 2 pixels. The top left pixel is black, the top right and bottom left pixels are gray, and the bottom right pixel is white. Such an image may be encoded as a PGM as follows. ( # starts a comment in PGM files.) # image.pgm # This is the header. P2 2 2 255 # And these are our 4 pixel values. 0 127 127 255","title":"Example"},{"location":"001_image_basics/parsing_pixel_data/challenge/#bitmap-hint","text":"Recall the documentation of the height_px field of the bitmap V4 header. Pixel data in a bitmap is stored in one of two ways, depending on the sign of this field.","title":"Bitmap Hint"},{"location":"001_image_basics/parsing_pixel_data/implementation/","text":"Parsing Pixel Data \u00b6 Implementation \u00b6 As mentioned in Challenge , we will produce a PGM image to visualize our parsed pixels. We extend our tool we made in the previous Implementation by adding a new optional command-line argument, --pgm-outdir . If the user specifies this, we convert the specified bitmap image into a PGM image. Otherwise, we print the file metadata as we did previously. Below we show the changes to main() interleaved with our previous code. import os # ... def main (): parser = argparse . ArgumentParser ( description = \"Limited-functionality bitmap parser\" ) parser . add_argument ( \"image\" , help = \"An image file pathname\" ) parser . add_argument ( \"--pgm-outdir\" , help = \"A path to a directory to write a PGM output file into\" ) args = parser . parse_args () with open ( args . image , \"rb\" ) as f : data = f . read () image = BitmapV4 ( data ) if args . pgm_outdir : os . makedirs ( args . pgm_outdir , exist_ok = True ) with open ( os . path . join ( args . pgm_outdir , \"image.pgm\" ), \"w\" ) as f : f . write ( image . as_pgm ()) else : print ( image ) BitmapV4.as_pgm is straightforward, the only trick here being that we iterate over the number of rows (the height) in reverse if the height is positive. class BitmapV4 : def __init__ ( self , data ): # ... self . pixels = list ( data [ self . file_header . pixel_data_offset_bytes :]) def as_pgm ( self ): \"\"\" Return an ASCII string encoding this iamge as a PGM. \"\"\" width = self . info_header . width_px height = self . info_header . height_px pgm = \"P2 \\n \" pgm += f \" { width } { height } \\n \" pgm += f \" { self . info_header . num_colors_required - 1 } \\n \" # If the pixel array is stored bottom-up, we reverse its rows. height_iter = reversed ( range ( height )) if height > 0 else range ( height ) for h in height_iter : for pixel in range ( h * width , h * width + width ): pgm += f \" { self . pixels [ pixel ] } \\n \" return pgm We can view our new image to confirm that we converted the grayscale bitmap V4 to a PGM correctly. $ ./bp.py --pgm-outdir /tmp test/data/2021-02-22-tokyo-skytree-grayscale.bmp # `eog` means Eye of Gnome and is the default image viewer in Ubuntu. $ eog /tmp/image.pgm","title":"Implementation"},{"location":"001_image_basics/parsing_pixel_data/implementation/#parsing-pixel-data","text":"","title":"Parsing Pixel Data"},{"location":"001_image_basics/parsing_pixel_data/implementation/#implementation","text":"As mentioned in Challenge , we will produce a PGM image to visualize our parsed pixels. We extend our tool we made in the previous Implementation by adding a new optional command-line argument, --pgm-outdir . If the user specifies this, we convert the specified bitmap image into a PGM image. Otherwise, we print the file metadata as we did previously. Below we show the changes to main() interleaved with our previous code. import os # ... def main (): parser = argparse . ArgumentParser ( description = \"Limited-functionality bitmap parser\" ) parser . add_argument ( \"image\" , help = \"An image file pathname\" ) parser . add_argument ( \"--pgm-outdir\" , help = \"A path to a directory to write a PGM output file into\" ) args = parser . parse_args () with open ( args . image , \"rb\" ) as f : data = f . read () image = BitmapV4 ( data ) if args . pgm_outdir : os . makedirs ( args . pgm_outdir , exist_ok = True ) with open ( os . path . join ( args . pgm_outdir , \"image.pgm\" ), \"w\" ) as f : f . write ( image . as_pgm ()) else : print ( image ) BitmapV4.as_pgm is straightforward, the only trick here being that we iterate over the number of rows (the height) in reverse if the height is positive. class BitmapV4 : def __init__ ( self , data ): # ... self . pixels = list ( data [ self . file_header . pixel_data_offset_bytes :]) def as_pgm ( self ): \"\"\" Return an ASCII string encoding this iamge as a PGM. \"\"\" width = self . info_header . width_px height = self . info_header . height_px pgm = \"P2 \\n \" pgm += f \" { width } { height } \\n \" pgm += f \" { self . info_header . num_colors_required - 1 } \\n \" # If the pixel array is stored bottom-up, we reverse its rows. height_iter = reversed ( range ( height )) if height > 0 else range ( height ) for h in height_iter : for pixel in range ( h * width , h * width + width ): pgm += f \" { self . pixels [ pixel ] } \\n \" return pgm We can view our new image to confirm that we converted the grayscale bitmap V4 to a PGM correctly. $ ./bp.py --pgm-outdir /tmp test/data/2021-02-22-tokyo-skytree-grayscale.bmp # `eog` means Eye of Gnome and is the default image viewer in Ubuntu. $ eog /tmp/image.pgm","title":"Implementation"},{"location":"001_image_basics/parsing_pixel_data/theory/","text":"Parsing Pixel Data \u00b6 Theory \u00b6 If we intended for the bitmap metadata-parsing tool we wrote earlier to be a general image-processing tool, we'd want a way to parse a variety of image types and present their pixel data in a single format, independent of the original file type. When parsing pixel data from a file, you need to consider two things primarily. The first is general metadata such as bits per pixel, the color space the pixels are encoded in, number of channels, and image width and height. The second is whether or not you can simply read the values as binary out of the image file or if you first need to decompress the pixel data. In our specific case, with a grayscale bitmap v4 image with a width evenly divisible by 4 [recall from the previous section that a row of a bitmap's pixel array is padded to be evenly divisible by 4], we made our life very easy. The pixels are packed contiguously as individual bytes right in the file--no decompression necessary or color channels to deal with. We won't cover compression here. When you're dealing with pixels in RAM later on, which is what we want to focus more on, they will be uncompressed. Regarding pixel encoding, though, if images have C channels, W width, and H height, then their pixel values are often encoded in what we call CHW (sometimes CWH) or HWC (sometimes WHC). CHW \u00b6 Think of CHW, for example, as \"channels, then height, then width,\" meaning that in the file's pixel array we first have all pixels (width * height) for the first color channel, and then the next set of pixels (width * height) for the second color channel, etc. If pixels were encoded as CHW, we could iterate over a flat array of pixels as for c in range ( CHANNELS ): for h in range ( HEIGHT ): for w in range ( WIDTH ): pixel_value = pixel_data [ c * WIDTH * HEIGHT + h * WIDTH + w ] Note that in CHW the first dimension (channels) is the outermost loop and the last dimension (width) is the innermost loop. Seen another way, the width value changes the fastest, then the height, and lastly the channels. If we drew the array for a 3-channel image and represented coordinates as (row, column) , it would look like (0, 0)---------------------------------------------------(0, WIDTH - 1) | | | Channel 1 | | | | | (HEIGHT - 1, 0)------------------------------------------(HEIGHT - 1, WIDTH - 1) | | | Channel 2 | | | | | (2 * HEIGHT - 2, 0)----------------------------------(2 * HEIGHT - 2, WIDTH - 1) | | | Channel 3 | | | | | +--------------------------------------------------------------+ HWC \u00b6 The other popular encoding interleaves the channel values for each pixel. We could iterate over a flat array of such pixels as for h in range ( HEIGHT ): for w in range ( WIDTH ): for c in range ( CHANNELS ): pixel_value = pixel_data [ w * CHANNELS + h * WIDTH * CHANNELS + c ] If we are dealing with RGB (the red-green-blue color space) and represent a pixel's channel values as Rn , Gn , Bn , where n is the index of a particular pixel in the pixel data, the memory layout looks like Index: 0 1 2 3 4 5 ... +----+----+----+----+----+----+--------+ | R1 | G1 | B1 | R2 | G2 | B2 | <etc.> | +----+----+----+----+----+----+--------+","title":"Theory"},{"location":"001_image_basics/parsing_pixel_data/theory/#parsing-pixel-data","text":"","title":"Parsing Pixel Data"},{"location":"001_image_basics/parsing_pixel_data/theory/#theory","text":"If we intended for the bitmap metadata-parsing tool we wrote earlier to be a general image-processing tool, we'd want a way to parse a variety of image types and present their pixel data in a single format, independent of the original file type. When parsing pixel data from a file, you need to consider two things primarily. The first is general metadata such as bits per pixel, the color space the pixels are encoded in, number of channels, and image width and height. The second is whether or not you can simply read the values as binary out of the image file or if you first need to decompress the pixel data. In our specific case, with a grayscale bitmap v4 image with a width evenly divisible by 4 [recall from the previous section that a row of a bitmap's pixel array is padded to be evenly divisible by 4], we made our life very easy. The pixels are packed contiguously as individual bytes right in the file--no decompression necessary or color channels to deal with. We won't cover compression here. When you're dealing with pixels in RAM later on, which is what we want to focus more on, they will be uncompressed. Regarding pixel encoding, though, if images have C channels, W width, and H height, then their pixel values are often encoded in what we call CHW (sometimes CWH) or HWC (sometimes WHC).","title":"Theory"},{"location":"001_image_basics/parsing_pixel_data/theory/#chw","text":"Think of CHW, for example, as \"channels, then height, then width,\" meaning that in the file's pixel array we first have all pixels (width * height) for the first color channel, and then the next set of pixels (width * height) for the second color channel, etc. If pixels were encoded as CHW, we could iterate over a flat array of pixels as for c in range ( CHANNELS ): for h in range ( HEIGHT ): for w in range ( WIDTH ): pixel_value = pixel_data [ c * WIDTH * HEIGHT + h * WIDTH + w ] Note that in CHW the first dimension (channels) is the outermost loop and the last dimension (width) is the innermost loop. Seen another way, the width value changes the fastest, then the height, and lastly the channels. If we drew the array for a 3-channel image and represented coordinates as (row, column) , it would look like (0, 0)---------------------------------------------------(0, WIDTH - 1) | | | Channel 1 | | | | | (HEIGHT - 1, 0)------------------------------------------(HEIGHT - 1, WIDTH - 1) | | | Channel 2 | | | | | (2 * HEIGHT - 2, 0)----------------------------------(2 * HEIGHT - 2, WIDTH - 1) | | | Channel 3 | | | | | +--------------------------------------------------------------+","title":"CHW"},{"location":"001_image_basics/parsing_pixel_data/theory/#hwc","text":"The other popular encoding interleaves the channel values for each pixel. We could iterate over a flat array of such pixels as for h in range ( HEIGHT ): for w in range ( WIDTH ): for c in range ( CHANNELS ): pixel_value = pixel_data [ w * CHANNELS + h * WIDTH * CHANNELS + c ] If we are dealing with RGB (the red-green-blue color space) and represent a pixel's channel values as Rn , Gn , Bn , where n is the index of a particular pixel in the pixel data, the memory layout looks like Index: 0 1 2 3 4 5 ... +----+----+----+----+----+----+--------+ | R1 | G1 | B1 | R2 | G2 | B2 | <etc.> | +----+----+----+----+----+----+--------+","title":"HWC"}]}